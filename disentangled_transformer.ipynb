{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design word embedding and positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$   x_i=embed(s_{1:T};(E,P))_i=Ee_{s_i}+Pe_i \\quad for\\enspace i=1,2,\\cdots,T$$\n",
    "\n",
    "We choose to use $10\\times 10$ orthogonal matrix to initialize $E$ and use positional encoding in *attention is all you need* to set $P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=20\n",
    "S=10\n",
    "d=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 30)\n"
     ]
    }
   ],
   "source": [
    "# set d=S=10,T=20\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#dim(E)=10*10, set E as an 10*10 orthonormal matrix\n",
    "#use QR decomposition to generate E\n",
    "rand_E=np.random.randn(S,S)\n",
    "E,_=np.linalg.qr(rand_E)\n",
    "# print(E@E.T)\n",
    "\n",
    "#dime(P)=10*20\n",
    "def positional_encoding(d, T):\n",
    "    # Initialize the positional encoding matrix\n",
    "    pos_enc = np.zeros((T, d))\n",
    "    \n",
    "    # Each position in the time step\n",
    "    for pos in range(T):\n",
    "        for i in range(0, d):\n",
    "            if i % 2 == 0:\n",
    "                # Apply the sine function for even indices\n",
    "                pos_enc[pos, i] = np.sin(pos / (10000 ** (i / d)))\n",
    "            else:\n",
    "                # Apply the cosine function for odd indices\n",
    "                pos_enc[pos, i] = np.cos(pos / (10000 ** ((i - 1) / d)))\n",
    "    \n",
    "    pos_enc=np.array(pos_enc).T\n",
    "\n",
    "    return pos_enc\n",
    "\n",
    "# Dimensionality and number of positions\n",
    "dim = 10\n",
    "num_pos = 20\n",
    "\n",
    "# Get the positional encoding matrix\n",
    "P = positional_encoding(dim, num_pos)\n",
    "\n",
    "#Concatenate E and P\n",
    "\n",
    "EP=np.concatenate((E, P), axis=1)\n",
    "print(EP.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tilde{X}^T=\\begin{bmatrix}\n",
    "    e_{s_1}& e_{s_2}&\\cdots&e_{s_T}\\\\\n",
    "    e_1&e_2&\\cdots&e_T\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "    \\mathcal{E}_{s_{1:T}}\\\\\n",
    "    \\mathbb{I}_{T}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Generate $\\mathbb{I}_{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fcfe24a27f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "I_t=np.identity(20)\n",
    "plt.imshow(I_t, cmap='hot')  # 'hot' is a popular colormap for heatmaps\n",
    "plt.colorbar()  # Show color scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the causal graph. \n",
    "\n",
    "1. Derive the parent node vector with length $T=[t_1,t_2,\\cdots,t_T]$.\n",
    "2. In the vector, let $t_i=0$ denotes that node $i$ has no parent, i.e. the node follows the prior distribution.\n",
    "3. Let $t_i=j$ denote that node $i$'s parent is node $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of causal graph and their visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1:\n",
    "\n",
    "$$p(1)=0,p(2i)=2i-1,\\enspace \\forall i>0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fd019395160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p=np.zeros((22,22))\n",
    "for i in range(1,20):\n",
    "    if (i+1)%2==0:\n",
    "        p[i,i-1]=1\n",
    "\n",
    "plt.imshow(p, cmap='hot')  # 'hot' is a popular colormap for heatmaps\n",
    "plt.colorbar()  # Show color scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Triansition matrix\n",
    "\n",
    "The prior $P_\\pi$ is choosen so that each row of $\\pi$ is sampled i.i.d. from the Dirichlet distribution with parameter $\\alpha$, i.e. $\\pi(\\cdot|s)\\sim Dir(\\alpha\\cdot 1_S)$, for varying values of $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "Transition_matrix=np.zeros((10,10))\n",
    "for i in range(1,11):\n",
    "    one_s=np.ones(10)\n",
    "    alpha=np.random.dirichlet(i*one_s)\n",
    "    Transition_matrix[i-1]=alpha\n",
    "\n",
    "# check the sum of each row is 1\n",
    "print(np.sum(Transition_matrix,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the stationary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the validity of the stationary distribution:\n",
      " 3.608224830031759e-16\n"
     ]
    }
   ],
   "source": [
    "# Calculate the left eigenvectors and eigenvalues\n",
    "eigenvalues, left_eigenvectors = np.linalg.eig(Transition_matrix.T)\n",
    "\n",
    "# Find the index of the eigenvalue closest to 1\n",
    "index = np.argmin(np.abs(eigenvalues - 1))\n",
    "\n",
    "# Extract the corresponding left eigenvector and normalize it\n",
    "stationary_distribution = np.real(left_eigenvectors[:, index])\n",
    "stationary_distribution /= stationary_distribution.sum()\n",
    "\n",
    "# print(\"Stationary Distribution:\\n\", stationary_distribution)\n",
    "\n",
    "# Check the validity of the stationary distribution\n",
    "print(\"Check the validity of the stationary distribution:\\n\", sum(np.abs(stationary_distribution @ Transition_matrix-stationary_distribution)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random sequence with causal structure\n",
    "\n",
    "There are 20 nodes and each nodes has 10 potential status\n",
    "\n",
    "We need to generate the status of each node sequentially\n",
    "\n",
    "1. When the node has no parent, its status is determined by the stationary distribution\n",
    "2. When the node $i$ has parent $j$, its status is determined by $\\pi(\\cdot|s_{p(i)})=\\pi(\\cdot|s_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parent vector where 0 represents no parent\n",
    "Parent_vec=np.array([0,1,0,3,0,5,0,7,0,9,0,11,0,13,0,15,0,17,0,0,20])\n",
    "\n",
    "# print(T[3])\n",
    "\n",
    "#Generate iter random sequence with causal structure\n",
    "\n",
    "iter=100000\n",
    "Status=np.empty((iter,T+1))\n",
    "\n",
    "for j in range(iter):\n",
    "\n",
    "    #i is the index of the node\n",
    "    for i in range(T-1):\n",
    "        #If the node has no parent, the status of the node is generated from the stationary distribution\n",
    "        if Parent_vec[i]==0:\n",
    "            Status[j,i]=np.random.choice(range(S),1,p=stationary_distribution)\n",
    "        \n",
    "        else:\n",
    "            #The parent of node i is Parent_vec[i]\n",
    "            #The status of parent node is Status[j,Parent_vec[i]-1]\n",
    "            #The conditional probability of the status of node i given its parent node Parent_vec[i] is Transition_matrix[Status[Parent_vec[i]-1]]\n",
    "            Status[j,i]=np.random.choice(range(S),1,p=Transition_matrix[int(Status[j,Parent_vec[i]-1])])\n",
    "\n",
    "    #The status of the node T is generated from the uniform distribution    \n",
    "    Status[j,T-1]=np.random.choice(range(S),1)\n",
    "\n",
    "    #The status of the node T+1 is the child of the node T\n",
    "    Status[j,T]=np.random.choice(range(S),1,p=Transition_matrix[int(Status[j,T-1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Status=Status.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 21)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Status.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the generated data\n",
    "\n",
    "np.savetxt(\"Status_2024_04_30.txt\", Status, fmt='%d')  # '%d' for integer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Status of the last node\n",
    "# print(Status[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that \n",
    "\n",
    "$$\\tilde{X}^T=\\begin{bmatrix}\n",
    "    e_{s_1}& e_{s_2}&\\cdots&e_{s_T}\\\\\n",
    "    e_1&e_2&\\cdots&e_T\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "    \\mathcal{E}_{s_{1:T}}\\\\\n",
    "    \\mathbb{I}_{T}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "we have generate $\\mathbb{I}_{T}$ before and we need to generate $\\mathcal{E}_{s_{1:T}}$ for each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_10=np.identity(S)\n",
    "\n",
    "X_tilde_T=np.empty((iter,S+T,T))\n",
    "\n",
    "for i in range(iter):\n",
    "\n",
    "    epsilon_1_T=np.zeros((S,T))\n",
    "\n",
    "    #print(T)\n",
    "\n",
    "    for k in range(T):\n",
    "        epsilon_1_T[:,int(k)]=I_10[:,int(Status[i,int(k)])]\n",
    "\n",
    "    #print(Status[0])\n",
    "\n",
    "    X_tilde_T[i]=np.concatenate((epsilon_1_T,I_t),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 30, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tilde_T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{equation}\n",
    "    \\begin{split}\n",
    "        h_T^{(1)^T}\\tilde A^{(2)}h_i&=[\\tilde x_T,attn(\\tilde X;\\tilde A^{(1)})_T]\\begin{bmatrix}\n",
    "            0_{S\\times S} & 0_{S\\times T} & A^{(2)} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & 0_{T\\times T} & 0_{T\\times S} & 0_{T\\times T}\\\\\n",
    "            0_{S\\times S} & 0_{S\\times T} & 0_{S\\times S} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & 0_{T\\times T} & 0_{T\\times S} & 0_{T\\times T}\\\\\n",
    "        \\end{bmatrix}\\begin{bmatrix}\n",
    "            \\tilde x_i^T\\\\\n",
    "            attn(\\tilde X;\\tilde A^{(1)})_i^T\n",
    "        \\end{bmatrix}\\\\\n",
    "        &=\\tilde x_T\\begin{bmatrix}\n",
    "            A^{(2)} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & 0_{T\\times T}\n",
    "        \\end{bmatrix}attn(\\tilde X;\\tilde A^{(1)})_i^T\\\\\n",
    "        &=\\textcolor{red}{[e_{s_T}^T,e_T^T]}\\begin{bmatrix}\n",
    "            A^{(2)} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & 0_{T\\times T}\n",
    "        \\end{bmatrix}attn(\\tilde X;\\tilde A^{(1)})_i^T\\\\\n",
    "    \\end{split}\n",
    "\\end{equation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tilde_T[0,:,-1].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{equation}\n",
    "    \\begin{split}\n",
    "        h_T^{(1)^T}\\tilde A^{(2)}h^{(1)}&=\\textcolor{red}{[e_{s_T}^T,e_T^T]}\\begin{bmatrix}\n",
    "            A^{(2)} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & 0_{T\\times T}\n",
    "        \\end{bmatrix}attn(\\tilde X;\\tilde A^{(1)})^T\\\\\n",
    "        &=\\bar x_T^TA^{(2)}\\bar X^T\\mathcal{S}(MASK(A^{(1)}))^T\n",
    "    \\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "where $\\textcolor{red}{\\bar x_T^T}=e_{S_T}^T$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tilde_T[0,0:10,-1].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\bar X^T=[e_{S_1},e_{S_2},\\cdots,e_{S_T}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tilde_T[0,0:10,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Lemma 1 tell us that the output of Transformer can be simplified as \n",
    "\n",
    "$$\n",
    "\\widetilde{TF}_{\\tilde\\theta}(S_{1:T})=\\bar X^T\\mathcal{S}\\bigl(\\mathcal{S}(MASK(A^{(1)}))\\bar XA^{(2)^T}\\bar x_T\\bigr)\n",
    "$$\n",
    "\n",
    "Notice that the out softmax is column wise and the inner softmax is row wise.\n",
    "\n",
    "We can simplify the output of transformer as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define MASK function, where MASK(M_{ij})=M_{ij} if i>=j, otherwise -inf\n",
    "def MASK(M):\n",
    "\n",
    "    # Number of rows and columns\n",
    "    num_rows, num_cols = M.shape\n",
    "\n",
    "    # Create a new matrix for the masked results\n",
    "    masked_matrix = np.full_like(M, fill_value=-np.inf, dtype=float)\n",
    "\n",
    "    # Apply the condition i >= j\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            if i >= j:\n",
    "                masked_matrix[i, j] = M[i, j]\n",
    "\n",
    "    return masked_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from scipy.special import softmax\n",
    "\n",
    "#store the output of transformer\n",
    "TF=np.empty((S,iter))\n",
    "\n",
    "delta=1e-3\n",
    "\n",
    "#define TF+delta\n",
    "TF_delta=np.empty((S,iter))\n",
    "\n",
    "# A_1=Variable(torch.zeros(T, T), requires_grad=True)\n",
    "# A_2=Variable(torch.zeros(S, S), requires_grad=True)\n",
    "\n",
    "beta_0=1e-3\n",
    "\n",
    "#initialize A_1 and A_2\n",
    "A_1=np.zeros((T,T))\n",
    "A_2=beta_0*np.identity(S)\n",
    "\n",
    "\n",
    "#Compute outputs of transformer\n",
    "for i in range(iter):\n",
    "    X_T=X_tilde_T[i,0:10,:]\n",
    "    x_T=X_tilde_T[i,0:10,-1]#.reshape(1,-1)\n",
    "    TF[:,i]=X_T@ softmax(softmax(MASK(A_1),axis=1)@X_T.T@ A_2.T@x_T.T,axis=0)\n",
    "    \n",
    "    #normalize\n",
    "    TF[:,i]=TF[:,i]/sum(TF[:,i])\n",
    "\n",
    "    #store TF+delta\n",
    "    TF_delta[:,i]=TF[:,i]+delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\widetilde{TF}_{\\tilde\\theta}(S_{1:T})=\\bar X^T\\mathcal{S}\\bigl(\\mathcal{S}(MASK(A^{(1)}))\\bar XA^{(2)^T}\\bar x_T\\bigr)\n",
    "$$\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        attn(\\tilde h^{(0)};\\tilde{A}_1^{(1)})&=\\mathcal{S}(MASK(\\tilde h^{(0)}\\tilde{A}_1^{(1)}\\tilde h^{(0)T}))\\tilde h^{(0)}\\\\\n",
    "        &=S(MASK(\\tilde X Z^{(0)T}A_1Z^{(0)}\\tilde X^T))\\tilde X\\\\\n",
    "        &=S(MASK(h^{(0)} A_1h^{(0)T}))\\tilde X\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need to constrain the trainable entries of $\\widetilde{A}^{(1)}$ and $\\widetilde{A}^{(2)}$ as\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        \\tilde A^{(1)}&=\\begin{bmatrix}\n",
    "            0_{S\\times S} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & A^{(1)}_1\n",
    "        \\end{bmatrix}\\\\\n",
    "        % \\tilde A_2^{(1)}&=\\begin{bmatrix}\n",
    "        %     0_{S\\times S} & 0_{S\\times T}\\\\\n",
    "        %     0_{T\\times S} & A^{(1)}_2\n",
    "        % \\end{bmatrix}\\\\\n",
    "        \\tilde A^{(2)}&=\\begin{bmatrix}\n",
    "            0_{S\\times S} & 0_{S\\times T} & A^{(2)} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & 0_{T\\times T} & 0_{T\\times S} & 0_{T\\times T}\\\\\n",
    "            0_{S\\times S} & 0_{S\\times T} & 0_{S\\times S} & 0_{S\\times T}\\\\\n",
    "            0_{T\\times S} & 0_{T\\times T} & 0_{T\\times S} & 0_{T\\times T}\\\\\n",
    "        \\end{bmatrix}\\\\\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#S=10\n",
    "# T=20\n",
    "\n",
    "import torch\n",
    "\n",
    "# Example of defining a matrix\n",
    "total_matrix_A_1 = torch.randn(int(S+T), int(S+T), requires_grad=True)\n",
    "total_matrix_A_2 = torch.randn(int(2*S+2*T), int(2*S+2*T), requires_grad=True)\n",
    "\n",
    "# Define a mask where True means trainable\n",
    "mask_A_1 = torch.tensor([[True if (i in range(S,int(S+T))  and  j in range(int(S),int(S+T))) else False for j in range(int(S+T))] for i in range(int(S+T))])\n",
    "mask_A_2 = torch.tensor([[True if (i in range(0,S)  and  j in range(int(S+T),int(2*S+T))) else False for j in range(int(2*S+2*T))] for i in range(int(2*S+2*T))])\n",
    "\n",
    "# Hook to apply the mask to the gradients\n",
    "def apply_mask_1(grad):\n",
    "    return grad * mask_A_1.type_as(grad)\n",
    "\n",
    "def apply_mask_2(grad):\n",
    "    return grad * mask_A_2.type_as(grad)\n",
    "\n",
    "# Attach the hook\n",
    "total_matrix_A_1.register_hook(apply_mask_1)\n",
    "\n",
    "total_matrix_A_2.register_hook(apply_mask_2)\n",
    "\n",
    "\n",
    "\n",
    "# # Example usage in a dummy forward pass\n",
    "# output_2 = total_matrix_A_2.sum()\n",
    "# output_2.backward()\n",
    "\n",
    "\n",
    "# # Set print options\n",
    "# torch.set_printoptions(threshold=10_000)\n",
    "# # Check gradients\n",
    "# print(total_matrix_A_2.grad)\n",
    "\n",
    "\n",
    "\n",
    "# output_1 = total_matrix_A_1.sum()\n",
    "# output_1.backward()\n",
    "# print(total_matrix_A_1.grad[10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "for i in range(iter):\n",
    "    X_T=X_tilde_T[i,0:10,:]\n",
    "    x_T=X_tilde_T[i,0:10,-1]#.reshape(1,-1)\n",
    "    \n",
    "    h_0=X_T@EP\n",
    "\n",
    "    score=torch.matmul(torch.matmul(h_0,A_1),h_0.T)\n",
    "\n",
    "    TF[:,i]=X_T@ softmax(softmax(MASK(A_1),axis=1)@X_T.T@ A_2.T@x_T.T,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        L(\\theta)&=-\\mathbb{E}_{\\pi,S_{1:T}}\\bigl[\\sum_{s'\\in [S]}\\textcolor{red}{\\pi(s'|s_T)}\\log (f_\\theta(s_{1:T})_{s'}+\\epsilon)\\bigr]\\\\\n",
    "        % &=-\\frac{1}{S}\\mathbb{E}_{\\pi,X}\\bigl[\\sum_{s,s'\\in [S]}\\pi(s'|s)\\log (f_\\theta(X;s)_{s'}+\\epsilon)\\bigr]\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Since we already got $s_T$ for each random sequences *Status[:,-1]*, we can generate the conditional probability $\\pi(\\cdot|s_T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_given_ST=np.empty((S,iter))\n",
    "\n",
    "for i in range(iter):\n",
    "    pi_given_ST[:,i]=Transition_matrix[int(Status[i,-1])]\n",
    "\n",
    "# print(pi_given_ST.shape)\n",
    "\n",
    "#Store the target values\n",
    "np.savetxt(\"Target_2024_04_30.txt\", pi_given_ST, fmt='%f')  # '%d' for integer format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.819071921028783\n"
     ]
    }
   ],
   "source": [
    "loss=np.empty(iter)\n",
    "for i in range(iter):\n",
    "    loss[i]=-np.dot(pi_given_ST[:,i],np.log(TF_delta[:,i]))\n",
    "\n",
    "Loss=sum(loss)/iter\n",
    "print(Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use GD to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
